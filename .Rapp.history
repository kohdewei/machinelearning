?qt
s<-30
n<-9
a<-1100
error<-qt(0.75,df=n-1)*s/sqrt(n)
a-error
a+error
error<-qt(0.975,df=n-1)*s/sqrt(n)
a+error
a-error
a<--2
qt(0.975,df=n-1)*2.6/sqrt(n)
qt(0.975,df=n-1)*0.3/sqrt(n)
qt(0.975,df=n-1)*2.1/sqrt(n)
qt(0.975,df=n-1)*1.5/sqrt(n)
m1<-3
m2<-5
sd1<-0.6
sd2<-0.68
num1<-10
num2<-10
se <- sqrt(sd1*sd1/num1+sd2*sd2/num2)
se
qt(0.975,df=pmin(num1,num2)-1)*se
error<-qt(0.975,df=pmin(num1,num2)-1)*se
-2+error
-2-error
3-5
-2+error
-2-error
m1
m2
sd1
sd2
num1
num2
(m1-m2)-error
pmin(num1,num2)
pmin
?pmin
x<<-10
x
## Matrix inversion is a costly computation.  These #
## functions cache the inverse of a matrix so as to #
## avoid computing it repeatedly.#
#
## Creates a special "matrix" object that can cache#
## its inverse#
#
makeCacheMatrix <- function(x = matrix()) {#
	i <- NULL#
	set <- function(y) {#
		x <<- y#
		i <<- NULL#
	}#
	get <- function() x#
	setinverse <- function(inverse) i <<- inverse#
	getinverse <- function() i#
	list(set = set, get = get, #
		 setinverse = setinverse,#
		 getinverse = getinverse)#
}#
#
## Computes the inverse of a special "matrix" returned#
## by makeCacheMatrix.  If the inverse has already been#
## calculated (and the matrix has not changed), then the#
## cacheSolve will retrieve the inverse from the cache.#
#
cacheSolve <- function(x, ...) {#
	i <- x$getinverse()#
	if(!is.null(i)) {#
		return(i)#
	}#
	data <- x$get()#
	i <- solve(data, ...)#
	x$setinverse(i)#
	i#
}
?solve
?pnorm
?t.test
y1<-c(140,138,150,148,135)
y2<-c(132,135,151,146,130)
t.test(y1,y2,paired=TRUE)
?qt
qt(0.95, 9)
qt(0.975, 9)
qt(0.975, 9)*30
qt(0.975, 9)*30+1100
qt(0.975, 8)*30+1100
qt(0.9, 8)*30+1100
qt(0.95, 8)*30+1100
* (1+4)/2^4
(1+4)/(2^4)
1/100
10/1787
1/100
pt(10/1787,1/100)
?prop.test
library(MASS)
table(quine$Eth, quine$Sex)
class(table(quine$Eth, quine$Sex))
?table
as.table(c(1,2,3,.4))
as.table(a=1, b=2)
?as.table
cbind(c(1,100),c(10,1787))
as.table(cbind(c(1,100),c(10,1787)))
prop.test(as.table(cbind(c(1,100),c(10,1787))))
?prop.test
prop.test(as.table(cbind(c(1,100),c(10,1787))), alternative="less")
prop.test(as.table(cbind(c(1,100),c(10,1787))), alternative="more")
prop.test(as.table(cbind(c(1,100),c(10,1787))), alternative="greater")
prop.test(as.table(rbind(c(1,100),c(10,1787))), alternative="less")
?prop.test
library(datasets)
data(iris)
iris
library(datasets)
iris
iris$Species
iris[iris$Species]
str(iris)
library(datasets)
iris
iris["Sepal.Length"]
iris[["Species"]]
iris[["Species"]]=="virginica"
iris["Sepal.Length"] & iris[["Species"]]=="virginica"
str(iris)
iris$Sepal.Length[iris$Species=="virginica"]
mean(iris[["Species"]]=="virginica")
mean(iris$Sepal.Length[iris$Species=="virginica"])
available.packages
available.packages()
installed.packages
installed.packages()
x <- installed.packages()
str(x)
x[1]
x[2]
x[3]
x[4]
x
x$Built
dim(x)
x[1,1]
x[1,2]
x[1,3]
names(x)
x[1,]
x[,1]
x[1,
]
x
x[1,]
x[1,10]
x[1,10]x
x
x[,1]
x <- ggplot2, RDataMining, plyr, colorspace, stringr, RColorBrewer, reshape2, zoo, scales, car, dichromat, labeling, rJava, mvtnorm, bitops, foreign, XML, lattice, gtools, sp, gdata, Rcpp, Matrix, lmtest, survival, caTools,multcomp, knitr, xtable, xts, rpart, evaluate, RODBC, quadprog, tseries, nlme, lme4, reshape, sandwich, leaps, gplots, abind, randomForest, maps, igraph, formatR, maptools, RSQLite, KernSmooth, rgdal, effects, sem, vcd, XLConnect, markdown, timeSeries,RJSONIO, cluster, scatterplot3d, nnet, fBasics, forecast, quantreg, foreach, chron, plotrix, matrixcalc, aplpack, strucchange, iterators, kernlab, SparseM, tree, robustbase, devtools, latticeExtra, modeltools, xlsx, slam, relimp,
x <- "ggplot2, RDataMining, plyr, colorspace, stringr, RColorBrewer, reshape2, zoo, scales, car, dichromat, labeling, rJava, mvtnorm, bitops, foreign, XML, lattice, gtools, sp, gdata, Rcpp, Matrix, lmtest, survival, caTools,multcomp, knitr, xtable, xts, rpart, evaluate, RODBC, quadprog, tseries, nlme, lme4, reshape, sandwich, leaps, gplots, abind, randomForest, maps, igraph, formatR, maptools, RSQLite, KernSmooth, rgdal, effects, sem, vcd, XLConnect, markdown, timeSeries,RJSONIO, cluster, scatterplot3d, nnet, fBasics, forecast, quantreg, foreach, chron, plotrix, matrixcalc, aplpack, strucchange, iterators, kernlab, SparseM, tree, robustbase, devtools, latticeExtra, modeltools, xlsx, slam, relimp"
y<-strsplit(x,",")
y
trim(y)
install.packages("stringr", dependencies=TRUE)
require(stringr)
example(str_trim)
str_trim(y)
y
y[[1]]
y<-y[[1]]
y
str_trim(y)
y<-str_trim(y)
y
x<-#
#
    ahaz#
    arules#
    bigrf#
    bmrm#
    Boruta#
    bst#
    C50#
    caret#
    CORElearn#
    CoxBoost#
    Cubist#
    e1071 (core)#
    earth#
    elasticnet#
    ElemStatLearn#
    evtree#
    frbs#
    GAMBoost#
    gamboostLSS#
    gbm (core)#
    glmnet#
    glmpath#
    GMMBoost#
    grplasso#
    grpreg#
    hda#
    hdi#
    ipred#
    kernlab (core)#
    klaR#
    lars#
    lasso2#
    LiblineaR#
    LogicReg#
    maptree#
    mboost (core)#
    mvpart#
    ncvreg#
    nnet (core)#
    oblique.tree#
    pamr#
    party#
    partykit#
    penalized#
    penalizedLDA#
    penalizedSVM#
    quantregForest#
    randomForest (core)#
    randomForestSRC#
    rattle#
    rda#
    rdetools#
    REEMtree#
    relaxo#
    rgenoud#
    rgp#
    Rmalschains#
    rminer#
    ROCR#
    RoughSets#
    rpart (core)#
    RPMM#
    RSNNS#
    RWeka#
    RXshrink#
    sda#
    stabs#
    svmpath#
    tgp#
    tree#
    varSelRF
x<-"#
#
    ahaz#
    arules#
    bigrf#
    bmrm#
    Boruta#
    bst#
    C50#
    caret#
    CORElearn#
    CoxBoost#
    Cubist#
    e1071 (core)#
    earth#
    elasticnet#
    ElemStatLearn#
    evtree#
    frbs#
    GAMBoost#
    gamboostLSS#
    gbm (core)#
    glmnet#
    glmpath#
    GMMBoost#
    grplasso#
    grpreg#
    hda#
    hdi#
    ipred#
    kernlab (core)#
    klaR#
    lars#
    lasso2#
    LiblineaR#
    LogicReg#
    maptree#
    mboost (core)#
    mvpart#
    ncvreg#
    nnet (core)#
    oblique.tree#
    pamr#
    party#
    partykit#
    penalized#
    penalizedLDA#
    penalizedSVM#
    quantregForest#
    randomForest (core)#
    randomForestSRC#
    rattle#
    rda#
    rdetools#
    REEMtree#
    relaxo#
    rgenoud#
    rgp#
    Rmalschains#
    rminer#
    ROCR#
    RoughSets#
    rpart (core)#
    RPMM#
    RSNNS#
    RWeka#
    RXshrink#
    sda#
    stabs#
    svmpath#
    tgp#
    tree#
    varSelRF#
"
y2<-strsplit(x,"")
y2
x<-"#
#
    ahaz#
    arules#
    bigrf#
    bmrm#
    Boruta#
    bst#
    C50#
    caret#
    CORElearn#
    CoxBoost#
    Cubist#
    e1071 (core)#
    earth#
    elasticnet#
    ElemStatLearn#
    evtree#
    frbs#
    GAMBoost#
    gamboostLSS#
    gbm (core)#
    glmnet#
    glmpath#
    GMMBoost#
    grplasso#
    grpreg#
    hda#
    hdi#
    ipred#
    kernlab (core)#
    klaR#
    lars#
    lasso2#
    LiblineaR#
    LogicReg#
    maptree#
    mboost (core)#
    mvpart#
    ncvreg#
    nnet (core)#
    oblique.tree#
    pamr#
    party#
    partykit#
    penalized#
    penalizedLDA#
    penalizedSVM#
    quantregForest#
    randomForest (core)#
    randomForestSRC#
    rattle#
    rda#
    rdetools#
    REEMtree#
    relaxo#
    rgenoud#
    rgp#
    Rmalschains#
    rminer#
    ROCR#
    RoughSets#
    rpart (core)#
    RPMM#
    RSNNS#
    RWeka#
    RXshrink#
    sda#
    stabs#
    svmpath#
    tgp#
    tree#
    varSelRF#
"
x
y2<-strsplit(x,"\n")
y2
y2 <- str_trim(y2)
y2 <- str_trim(y2[[1]])
y2
y2[3:]
y2[3:,]
y2[3:5]
y2[3:10000]
dim(y2)
len(y2)
length(y2)
y2
y2[3:73]
y2<-y2[3:73]
y2<-y2[-c(12,20,29,36,39,48,61)]
y2
y
y<- c(y,y2)
y
sort(y)
duplicated(y)
sort(y)
y<-sort(y)
duplicated(y)
y[duplicated(y)]
y <- y[-c(135)]
y
duplicated(y)
y
paste(y,", ")
paste(y,collapse=", ")
installed.packages()
y
installed.packages()
x<-installed.packages()
y
x[,1]
x[[,1]]
x[,1]
y
x
x[4,1]
x[4,4]
x[1,4]
x[,4]
names(x[,4])
names(x[,4])[1]
names(x[,4])[x[,4]!="base"]
names(x[,4])[x[,4]!="base" | is.na(x[,4])]
x<-names(x[,4])[x[,4]!="base" | is.na(x[,4])]
x
y
y <- c(x,y)
y
sort(y)
y<-sort(y)
duplicated(y)
y[!duplicated(y)]
y<-y[!duplicated(y)]
duplicated(y)
y
y<-sort(y)
y
paste(y,collapse=", ")
oauth_endpoints("github")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("Test", "6a4486d9d8285138cc655aef5751b003bfa28eaf",secret=NULL)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
myapp <- oauth_app("Test", "42c3a2d1f35bc01f2011",secret="3e5289c2779407c95fc075f9af4798fd49d6db8e")
myapp <- oauth_app("github", "42c3a2d1f35bc01f2011",secret="3e5289c2779407c95fc075f9af4798fd49d6db8e")
library(caret)#
trainPml <- read.csv("pml-training.csv")#
testPml <- read.csv("pml-testing.csv")#
#
# data cleansing#
missingVar <- colSums(is.na(trainPml))==19216#
trainPml <- trainPml[!missingVar]#
testPml <- testPml[!missingVar]#
trainPml <- trainPml[-c(1:7)]#
testPml <- testPml[-c(1:7)]#
#
# data partitioning#
inTrain <- createDataPartition(y=trainPml$classe, p=0.6, list=FALSE)#
training <- trainPml[inTrain,]#
testing <- trainPml[-inTrain,]#
set.seed(12345)#
#
trainInd <- sample(nrow(training), 3000)#
training2 <- training[trainInd,]
fitControl <- trainControl(method="cv", number=4)#
modelFit <- train(classe~., data=training2, method="rf", prox=TRUE, trControl=fitControl)
?randomForest
modelFit <- randomForest(classe~., data=training2)
dim(training2)
str(training2)
trainPml <- read.csv("pml-training.csv", na.strings=c("NA",""))#
testPml <- read.csv("pml-testing.csv", na.strings=c("NA",""))
colSums(is.na(trainPml))
missingVar <- colSums(is.na(trainPml))==19216#
trainPml <- trainPml[!missingVar]#
testPml <- testPml[!missingVar]#
trainPml <- trainPml[-c(1:7)]#
testPml <- testPml[-c(1:7)]
inTrain <- createDataPartition(y=trainPml$classe, p=0.6, list=FALSE)#
training <- trainPml[inTrain,]#
testing <- trainPml[-inTrain,]#
set.seed(12345)
dim(training)
trainInd <- sample(nrow(training), 3000)#
training2 <- training[trainInd,]
names(training)
modelFit <- randomForest(classe~., data=training2)
modelFit
confusionMatrix(predict(modelFit, testing), testing$classe)
fitControl <- trainControl(method="cv", number=4)#
modelFit <- train(classe~., data=training, method="rf", prox=TRUE, trControl=fitControl)
modelFit
modelFit <- randomForest(classe~., data=training2)
confusionMatrix(predict(modelFit, testing), testing$classe)
modelFit <- randomForest(classe~., data=training)
confusionMatrix(predict(modelFit, testing), testing$classe)
answers <- as.character(predict(model, testing))
answers <- as.character(predict(modelFit, testing))
answers
answers <- as.character(predict(modelFit, testPml))
testPml
answers
pml_write_files = function(x){#
  n = length(x)#
  for(i in 1:n){#
    filename = paste0("problem_id_",i,".txt")#
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)#
  }#
}
pml_write_files()
pml_write_files(answers)
